{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from math import ceil\n",
    "%matplotlib qt\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Conv3D, MaxPooling2D, Flatten, Input, Activation, BatchNormalization, Dropout, Reshape\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.losses import categorical_crossentropy, MAPE\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(width, height, depth, filters=(16, 16, 16, 16, 16)):\n",
    "    input_shape = (height, width, depth)\n",
    "    chan_dim = -1\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    for (i, filter) in enumerate(filters):\n",
    "        if i == 0:\n",
    "            x = inputs\n",
    "            #x = Conv3D(filter, (3, 3, 1), padding=\"same\", activation=\"relu\")(x)\n",
    "            #x = BatchNormalization(axis=chan_dim)(x)\n",
    "            #x = Reshape(target_shape=(height,width,filter))(x)\n",
    "        #else:\n",
    "            # CONV => RELU => BN => POOL\n",
    "        x = Conv2D(filter, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
    "        x = BatchNormalization(axis=chan_dim)(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # flatten the volume, then FC => RELU => BN => DROPOUT\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(16, activation=\"relu\")(x)\n",
    "    x = BatchNormalization(axis=chan_dim)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    # apply another FC layer, this one to match the number of nodes\n",
    "    # coming out of the MLP\n",
    "    x = Dense(4, activation=\"linear\")(x)\n",
    "\n",
    "    # construct the CNN\n",
    "    model = Model(inputs, x)\n",
    "\n",
    "    # return the CNN\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = False\n",
    "train_model = True\n",
    "save_model = True\n",
    "test_model = True\n",
    "\n",
    "data_folder = 'thr_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating model...\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 636, 256, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 636, 256, 16)      160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 636, 256, 16)      64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 318, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 318, 128, 16)      2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 318, 128, 16)      64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 159, 64, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 159, 64, 16)       2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 159, 64, 16)       64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 79, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 79, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 79, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 39, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 39, 16, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 39, 16, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 19, 8, 16)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2432)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                38928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 48,820\n",
      "Trainable params: 48,628\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('creating model...')\n",
    "model = create_cnn(256, 636, 1)\n",
    "opt = Adam(lr=1e-3, decay=1e-3/200)\n",
    "model.compile(loss=\"mean_absolute_error\", optimizer=opt)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_model:\n",
    "    model.load_weights('thr_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training data...\n",
      "MidFlex-200205-01-train-images.npy\n",
      "(978, 636, 256, 1) (978, 4)\n",
      "training model...\n",
      "Train on 880 samples, validate on 98 samples\n",
      "Epoch 1/10\n",
      "880/880 [==============================] - 82s 94ms/sample - loss: 0.9055 - val_loss: 0.7474\n",
      "Epoch 2/10\n",
      "880/880 [==============================] - 80s 91ms/sample - loss: 0.6844 - val_loss: 1.8163\n",
      "Epoch 3/10\n",
      "880/880 [==============================] - 80s 91ms/sample - loss: 0.5684 - val_loss: 2.9381\n",
      "Epoch 4/10\n",
      "880/880 [==============================] - 81s 92ms/sample - loss: 0.4783 - val_loss: 4.1214\n",
      "Epoch 5/10\n",
      "880/880 [==============================] - 81s 92ms/sample - loss: 0.4027 - val_loss: 3.7360\n",
      "Epoch 6/10\n",
      "880/880 [==============================] - 81s 92ms/sample - loss: 0.3580 - val_loss: 3.2475\n",
      "Epoch 7/10\n",
      "880/880 [==============================] - 81s 92ms/sample - loss: 0.3289 - val_loss: 2.5900\n",
      "Epoch 8/10\n",
      "880/880 [==============================] - 81s 92ms/sample - loss: 0.2934 - val_loss: 1.8119\n",
      "Epoch 9/10\n",
      "880/880 [==============================] - 81s 92ms/sample - loss: 0.2678 - val_loss: 1.1134\n",
      "Epoch 10/10\n",
      "880/880 [==============================] - 81s 92ms/sample - loss: 0.2471 - val_loss: 0.4230\n",
      "PinFlex-200205-01-train-images.npy\n",
      "(978, 636, 256, 1) (978, 4)\n",
      "training model...\n",
      "Train on 880 samples, validate on 98 samples\n",
      "Epoch 1/10\n",
      "880/880 [==============================] - 81s 92ms/sample - loss: 0.4067 - val_loss: 0.4519\n",
      "Epoch 2/10\n",
      "880/880 [==============================] - 81s 92ms/sample - loss: 0.3209 - val_loss: 0.3712\n",
      "Epoch 3/10\n",
      "880/880 [==============================] - 81s 92ms/sample - loss: 0.2671 - val_loss: 0.3198\n",
      "Epoch 4/10\n",
      "880/880 [==============================] - 81s 92ms/sample - loss: 0.2226 - val_loss: 0.2350\n",
      "Epoch 5/10\n",
      "880/880 [==============================] - 82s 93ms/sample - loss: 0.2069 - val_loss: 0.1849\n",
      "Epoch 6/10\n",
      "880/880 [==============================] - 81s 92ms/sample - loss: 0.1918 - val_loss: 0.1636\n",
      "Epoch 7/10\n",
      "880/880 [==============================] - 81s 92ms/sample - loss: 0.1827 - val_loss: 0.1721\n",
      "Epoch 8/10\n",
      "880/880 [==============================] - 81s 92ms/sample - loss: 0.1774 - val_loss: 0.1575\n",
      "Epoch 9/10\n",
      "880/880 [==============================] - 81s 92ms/sample - loss: 0.1828 - val_loss: 0.1167\n",
      "Epoch 10/10\n",
      "880/880 [==============================] - 82s 94ms/sample - loss: 0.1818 - val_loss: 0.1224\n",
      "RinFlex-200205-01-train-images.npy\n",
      "(978, 636, 256, 1) (978, 4)\n",
      "training model...\n",
      "Train on 880 samples, validate on 98 samples\n",
      "Epoch 1/10\n",
      "880/880 [==============================] - 81s 92ms/sample - loss: 0.3399 - val_loss: 0.2551\n",
      "Epoch 2/10\n",
      "880/880 [==============================] - 81s 92ms/sample - loss: 0.2533 - val_loss: 0.1686\n",
      "Epoch 3/10\n",
      "880/880 [==============================] - 81s 92ms/sample - loss: 0.1972 - val_loss: 0.1415\n",
      "Epoch 4/10\n",
      "880/880 [==============================] - 81s 92ms/sample - loss: 0.1811 - val_loss: 0.1026\n",
      "Epoch 5/10\n",
      "880/880 [==============================] - 81s 92ms/sample - loss: 0.1831 - val_loss: 0.1034\n",
      "Epoch 6/10\n",
      "880/880 [==============================] - 81s 92ms/sample - loss: 0.1819 - val_loss: 0.0897\n",
      "Epoch 7/10\n",
      "880/880 [==============================] - 81s 92ms/sample - loss: 0.1784 - val_loss: 0.0933\n",
      "Epoch 8/10\n",
      "880/880 [==============================] - 81s 92ms/sample - loss: 0.1739 - val_loss: 0.1054\n",
      "Epoch 9/10\n",
      "880/880 [==============================] - 81s 92ms/sample - loss: 0.1714 - val_loss: 0.1047\n",
      "Epoch 10/10\n",
      "880/880 [==============================] - 81s 92ms/sample - loss: 0.1711 - val_loss: 0.1448\n",
      "ThrExt-200205-01-train-images.npy\n",
      "(978, 636, 256, 1) (978, 4)\n",
      "training model...\n",
      "Train on 880 samples, validate on 98 samples\n",
      "Epoch 1/10\n",
      "880/880 [==============================] - 81s 92ms/sample - loss: 0.4486 - val_loss: 0.2913\n",
      "Epoch 2/10\n",
      "880/880 [==============================] - 79s 90ms/sample - loss: 0.3599 - val_loss: 0.2070\n",
      "Epoch 3/10\n",
      "880/880 [==============================] - 79s 90ms/sample - loss: 0.2945 - val_loss: 0.1613\n",
      "Epoch 4/10\n",
      "880/880 [==============================] - 80s 91ms/sample - loss: 0.2699 - val_loss: 0.1306\n",
      "Epoch 5/10\n",
      "880/880 [==============================] - 81s 92ms/sample - loss: 0.2499 - val_loss: 0.1094\n",
      "Epoch 6/10\n",
      "880/880 [==============================] - 81s 92ms/sample - loss: 0.2382 - val_loss: 0.1113\n",
      "Epoch 7/10\n",
      "880/880 [==============================] - 81s 92ms/sample - loss: 0.2378 - val_loss: 0.1007\n",
      "Epoch 8/10\n",
      "880/880 [==============================] - 81s 92ms/sample - loss: 0.2267 - val_loss: 0.1166\n",
      "Epoch 9/10\n",
      "880/880 [==============================] - 82s 93ms/sample - loss: 0.2303 - val_loss: 0.1130\n",
      "Epoch 10/10\n",
      "880/880 [==============================] - 81s 92ms/sample - loss: 0.2243 - val_loss: 0.1134\n"
     ]
    }
   ],
   "source": [
    "if train_model:\n",
    "    print('loading training data...')\n",
    "    vera_train = [f for f in os.listdir(data_folder) if f.endswith('-train-images.npy')]\n",
    "    vico_train = [f for f in os.listdir(data_folder) if f.endswith('-train-angles.npy')]\n",
    "\n",
    "    for im,an in zip(vera_train,vico_train):\n",
    "        print(im)\n",
    "        im_data = np.load('{0}/{1}'.format(data_folder,im))[...,None]\n",
    "        an_data = np.load('{0}/{1}'.format(data_folder,an))[...,1:]\n",
    "        print(im_data.shape,an_data.shape)\n",
    "\n",
    "        print('training model...')\n",
    "        model.fit(im_data, an_data, validation_split=0.1, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model...\n"
     ]
    }
   ],
   "source": [
    "if save_model:\n",
    "    print('saving model...')\n",
    "    model.save('thr_model.h5', save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading testing data...\n",
      "MidFlex-200205-01-test-images.npy\n",
      "(420, 636, 256, 1) (420, 4)\n",
      "testing model...\n",
      "420/420 - 6s - loss: 0.3204\n",
      "PinFlex-200205-01-test-images.npy\n",
      "(420, 636, 256, 1) (420, 4)\n",
      "testing model...\n",
      "420/420 - 6s - loss: 0.4244\n",
      "RinFlex-200205-01-test-images.npy\n",
      "(420, 636, 256, 1) (420, 4)\n",
      "testing model...\n",
      "420/420 - 6s - loss: 0.3699\n",
      "ThrExt-200205-01-test-images.npy\n",
      "(420, 636, 256, 1) (420, 4)\n",
      "testing model...\n",
      "420/420 - 6s - loss: 0.2207\n"
     ]
    }
   ],
   "source": [
    "if test_model:\n",
    "    print('loading testing data...')\n",
    "    vera_test = [f for f in os.listdir(data_folder) if f.endswith('-test-images.npy')]\n",
    "    vico_test = [f for f in os.listdir(data_folder) if f.endswith('-test-angles.npy')]\n",
    "    fingers = ['thumb','index','middle','ring','pinky']\n",
    "    preds = np.zeros((420*len(vera_test),4))\n",
    "    reals = np.zeros((420*len(vera_test),4))\n",
    "    for i,(im,an) in enumerate(zip(vera_test,vico_test)):\n",
    "        print(im)\n",
    "        im_data = np.load('{0}/{1}'.format(data_folder,im))[...,None]\n",
    "        an_data = np.load('{0}/{1}'.format(data_folder,an))[...,1:]\n",
    "        print(im_data.shape,an_data.shape)\n",
    "\n",
    "        print('testing model...')\n",
    "        loss = model.evaluate(im_data, an_data, verbose=2)\n",
    "        predictions = model.predict(im_data)\n",
    "        preds[420*i:420*(i+1),...] = predictions\n",
    "        reals[420*i:420*(i+1),...] = an_data\n",
    "        for f,finger in enumerate(fingers[1:]):\n",
    "            plt.subplot(len(vera_test),4,4*i+f+1)\n",
    "            plt.plot(an_data[...,f]),plt.plot(predictions[...,f])\n",
    "            if i==0:\n",
    "                plt.title('{0} finger angle'.format(finger))\n",
    "            if f==0:\n",
    "                title = im.split('-')\n",
    "                plt.ylabel('-'.join([title[i] for i in [0,2]]),rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.46984805 0.24813758 0.32971035 0.28776812]\n"
     ]
    }
   ],
   "source": [
    "errs1 = np.sum(np.absolute(preds-reals),axis=0)/preds.shape[0]\n",
    "errs2 = np.sum(np.absolute(preds-reals[...,0][...,None]),axis=0)/preds.shape[0]\n",
    "errs3 = np.sum(np.absolute(preds-reals[...,1][...,None]),axis=0)/preds.shape[0]\n",
    "errs4 = np.sum(np.absolute(preds-reals[...,2][...,None]),axis=0)/preds.shape[0]\n",
    "errs5 = np.sum(np.absolute(preds-reals[...,3][...,None]),axis=0)/preds.shape[0]\n",
    "\n",
    "print(errs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33386602521834857\n",
      "0.28604171060560024\n",
      "0.3215410297271667\n",
      "0.35632081047973047\n",
      "0.36990101384832785\n"
     ]
    }
   ],
   "source": [
    "print(np.average(errs1))\n",
    "print(np.average(errs2))\n",
    "print(np.average(errs3))\n",
    "print(np.average(errs4))\n",
    "print(np.average(errs5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

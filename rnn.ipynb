{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision as tv\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovingFilterDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, array, window, label, transform=None):\n",
    "        self.array = array\n",
    "        self.window = window\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample = np.moveaxis(self.array[index:index+self.window,...],0,-1)\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample).float()\n",
    "        return (sample, self.label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.array.shape[0] - self.window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = True\n",
    "\n",
    "window_size = 20\n",
    "num_epochs = 15\n",
    "batch_size = 75\n",
    "class_folders = [\n",
    "            ['ball_data'],\n",
    "            ['bott_data'],\n",
    "            ['fist_data'],\n",
    "            ['ind_data'],\n",
    "            ['mid_data'],\n",
    "            ['rin_data'],\n",
    "            ['pin_data'],\n",
    "            ['thr_data']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"if load_data:\\n    print('loading training data as Dataset...')\\n    full_dataset = torch.load('rnn_dataset.pt')\\nelse:\\n    full_dataset = []\\n    print('loading training data as Numpy and coverting...')\\n    for i,folder_list in enumerate(class_folders):\\n        class_files = [os.path.join(l,f) for l in folder_list for f in os.listdir(l) if f.endswith('-train-images.npy')]\\n        for im in class_files:\\n            print(im)\\n            im_data = np.load(im)\\n            print(im_data.shape)\\n            full_dataset.append(MovingFilterDataset(im_data,window_size,i,transform=tv.transforms.ToTensor()))\\n    print('concatenating datasets...')\\n    full_dataset = torch.utils.data.ConcatDataset(full_dataset)\\n    print('saving dataset for later...')\\n    #torch.save(full_dataset, 'rnn_dataset.pt')\\n#loader = torch.utils.data.DataLoader(full_dataset,batch_size=30,shuffle=True)\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"if load_data:\n",
    "    print('loading training data as Dataset...')\n",
    "    full_dataset = torch.load('rnn_dataset.pt')\n",
    "else:\n",
    "    full_dataset = []\n",
    "    print('loading training data as Numpy and coverting...')\n",
    "    for i,folder_list in enumerate(class_folders):\n",
    "        class_files = [os.path.join(l,f) for l in folder_list for f in os.listdir(l) if f.endswith('-train-images.npy')]\n",
    "        for im in class_files:\n",
    "            print(im)\n",
    "            im_data = np.load(im)\n",
    "            print(im_data.shape)\n",
    "            full_dataset.append(MovingFilterDataset(im_data,window_size,i,transform=tv.transforms.ToTensor()))\n",
    "    print('concatenating datasets...')\n",
    "    full_dataset = torch.utils.data.ConcatDataset(full_dataset)\n",
    "    print('saving dataset for later...')\n",
    "    #torch.save(full_dataset, 'rnn_dataset.pt')\n",
    "#loader = torch.utils.data.DataLoader(full_dataset,batch_size=30,shuffle=True)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel1(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = torch.nn.ModuleDict({\n",
    "            'lstm': torch.nn.LSTM(636*256,32,batch_first=True),\n",
    "            'linear': torch.nn.Linear(32,len(class_folders)),\n",
    "            'sigmoid': torch.nn.Sigmoid()\n",
    "        })\n",
    "    def forward(self,x):\n",
    "        out,_ = self.model['lstm'](x)\n",
    "        out = self.model['linear'](out)\n",
    "        out = self.model['sigmoid'](out)\n",
    "        return out[:,-1,...]#.squeeze()\n",
    "    def loss_function(self,x,y):\n",
    "        output = self.forward(x)\n",
    "        loss = torch.nn.CrossEntropyLoss()(output,y)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel2(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = torch.nn.ModuleDict({\n",
    "            'conv1': torch.nn.Conv2d(window_size,window_size,5,stride=2),\n",
    "            'relu1': torch.nn.ReLU(),\n",
    "            'conv2': torch.nn.Conv2d(window_size,window_size,5,stride=2),\n",
    "            'relu2': torch.nn.ReLU(),\n",
    "            'lstm': torch.nn.LSTM(9516,32,batch_first=True),\n",
    "            'linear': torch.nn.Linear(32,len(class_folders)),\n",
    "            'sigmoid': torch.nn.Sigmoid()\n",
    "        })\n",
    "    def forward(self,x):\n",
    "        out = self.model['conv1'](x)\n",
    "        out = self.model['relu1'](out)\n",
    "        out = self.model['conv2'](out)\n",
    "        out = self.model['relu2'](out)\n",
    "        #out = torch.reshape(out,(batch_size,window_size,-1))\n",
    "        out = torch.reshape(out,(*(out.size()[0:2]), -1))\n",
    "        out,_ = self.model['lstm'](out)\n",
    "        out = self.model['linear'](out)\n",
    "        out = self.model['sigmoid'](out)\n",
    "        return out[:,-1,...]\n",
    "    def loss_function(self,x,y):\n",
    "        output = self.forward(x)\n",
    "        loss = torch.nn.CrossEntropyLoss()(output,y)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = MyModel2()\n",
    "if load_model:\n",
    "    network.load_state_dict(torch.load('rnn_network.pt'),strict=False)\n",
    "\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training data as Numpy and coverting...\n",
      "fist_data/FistRelax-200205-02-train-images.npy\n",
      "(978, 636, 256)\n",
      "ball_data/BallGrab-200205-01-train-images.npy\n",
      "(978, 636, 256)\n",
      "ind_data/IndFlex-200205-01-train-images.npy\n",
      "(978, 636, 256)\n",
      "Epoch 11 Batch 4 Loss: 1.60314333438873393\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-985774e26da2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-81-0f1566ba54bf>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \"\"\"\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mpic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;31m# backward compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('loading training data as Numpy and coverting...')\n",
    "files = [(i,os.path.join(d,f)) for i,l in enumerate(class_folders) for d in l for f in os.listdir(d) if f.endswith('-train-images.npy')]\n",
    "random.shuffle(files)\n",
    "\n",
    "losses = []\n",
    "for i,im in files:\n",
    "    print(im)\n",
    "    im_data = np.load(im)\n",
    "    print(im_data.shape)\n",
    "    dataset = MovingFilterDataset(im_data,window_size,i,transform=tv.transforms.ToTensor())\n",
    "    dataloader = torch.utils.data.DataLoader(dataset,batch_size=batch_size,shuffle=True,drop_last=True)\n",
    "    file_loss = []\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = []\n",
    "        for batch,(seq,labels) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            loss = network.loss_function(seq,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_val = loss.item()\n",
    "            print('Epoch',epoch,'Batch',batch,'Loss:',loss_val,end='\\r')\n",
    "            epoch_loss.append(loss_val)\n",
    "        file_loss.append(epoch_loss)\n",
    "    losses.append(file_loss)\n",
    "losses = np.array(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.save('train_losses_new3.npy',losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading testing data as Numpy and coverting...\n",
      "ball_data/BallGrab-200205-01-test-images.npy\n",
      "(420, 636, 256)\n",
      "fist_data/FistRelax-200205-01-test-images.npy\n",
      "(420, 636, 256)\n",
      "rin_data/RinFlex-200205-01-test-images.npy\n",
      "(420, 636, 256)\n",
      "ind_data/IndFlex-200205-01-test-images.npy\n",
      "(420, 636, 256)\n",
      "mid_data/MidFlex-200205-01-test-images.npy\n",
      "(420, 636, 256)\n",
      "thr_data/ThrExt-200205-01-test-images.npy\n",
      "(420, 636, 256)\n",
      "bott_data/BottGrab-200205-01-test-images.npy\n",
      "(420, 636, 256)\n",
      "pin_data/PinFlex-200205-01-test-images.npy\n",
      "(420, 636, 256)\n",
      "ball_data/BallGrab-200205-02-test-images.npy\n",
      "(420, 636, 256)\n",
      "ind_data/IndExt-200205-01-test-images.npy\n",
      "(420, 636, 256)\n",
      "fist_data/FistRelax-200205-02-test-images.npy\n",
      "(420, 636, 256)\n"
     ]
    }
   ],
   "source": [
    "print('loading testing data as Numpy and coverting...')\n",
    "test_files = [(i,os.path.join(d,f)) for i,l in enumerate(class_folders) for d in l for f in os.listdir(d) if f.endswith('-test-images.npy')]\n",
    "random.shuffle(test_files)\n",
    "\n",
    "labels = []\n",
    "preds = []\n",
    "for i,im in test_files:\n",
    "    print(im)\n",
    "    im_data = np.load(im)\n",
    "    print(im_data.shape)\n",
    "    dataset = MovingFilterDataset(im_data,window_size,i,transform=tv.transforms.ToTensor())\n",
    "    dataloader = torch.utils.data.DataLoader(dataset)\n",
    "    for i,(seq,label) in enumerate(dataloader):\n",
    "        pred = network(seq)\n",
    "        #print(pred)\n",
    "        pred = torch.argmax(pred)\n",
    "        labels.append(label.item())\n",
    "        preds.append(pred.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0 800   0   0   0   0   0]\n",
      " [  0   0 400   0   0   0   0   0]\n",
      " [  0   0 800   0   0   0   0   0]\n",
      " [  0   0 800   0   0   0   0   0]\n",
      " [  0   0 400   0   0   0   0   0]\n",
      " [  0   0 400   0   0   0   0   0]\n",
      " [  0   0 400   0   0   0   0   0]\n",
      " [  0   0 400   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "conf = confusion_matrix(labels,preds)\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe2c73356a0>]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(losses.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(network.state_dict(),'rnn_network.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = MyModel1()\n",
    "network.load_state_dict(torch.load('rnn_network.pt',strict=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading testing data as Numpy and coverting...\n"
     ]
    }
   ],
   "source": [
    "print('loading testing data as Numpy and coverting...')\n",
    "test_files = [(i,os.path.join(d,f)) for i,l in enumerate(class_folders) for d in l for f in os.listdir(d) if f.endswith('-test-images.npy')]\n",
    "random.shuffle(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 'rin_data/RinFlex-200205-01-test-images.npy'),\n",
       " (1, 'bott_data/BottGrab-200205-01-test-images.npy'),\n",
       " (2, 'fist_data/FistRelax-200205-02-test-images.npy'),\n",
       " (0, 'ball_data/BallGrab-200205-01-test-images.npy'),\n",
       " (3, 'ind_data/IndFlex-200205-01-test-images.npy'),\n",
       " (3, 'ind_data/IndExt-200205-01-test-images.npy'),\n",
       " (0, 'ball_data/BallGrab-200205-02-test-images.npy'),\n",
       " (2, 'fist_data/FistRelax-200205-01-test-images.npy'),\n",
       " (4, 'mid_data/MidFlex-200205-01-test-images.npy'),\n",
       " (7, 'thr_data/ThrExt-200205-01-test-images.npy'),\n",
       " (6, 'pin_data/PinFlex-200205-01-test-images.npy')]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
